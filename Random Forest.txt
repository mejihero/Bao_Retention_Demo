##############################################################################
##############################  import library  ##############################
##############################################################################




import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.externals import joblib

%matplotlib inline
sns.set(style = 'white', font_scale = 0.9)


from sklearn.externals import joblib


from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import GridSearchCV

from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.metrics import roc_auc_score

import scikitplot as skplt









################################################################################
##################  define the main function   #################################



def classifier_mod(X_train, y_train, X_test, y_test, sampName):
    
    ## print the shape of imported dataset
    print('X_train shape: ', X_train.shape)
    print('y_train shape: ', y_train.shape)
    print('X_test shape:', X_test.shape)
    print('y_test shape: ', y_test.shape)
    
    ## grid search for the optimal hyperparameters
    model = RandomForestClassifier(random_state = 123)
    
    param_grid = {'n_estimators': [200,500], 'max_depth': [3, None], 'max_features': [1,3,5,10],
                 'min_samples_split': [2, 5,10], 'min_samples_leaf': [1, 3,10], 'bootstrap': [True, False], 
                  'criterion': ['gini', 'entropy']}
    
    grid = GridSearchCV(estimator = model, param_grid = param_grid, scoring = 'roc_auc', n_jobs = -1, verbose = 1)
    grid.fit(X_train, y_train)
    
    print(grid.best_score_)
    print(grid.best_params_)
    
    ## fit the model with the optimal hyperparameters
    classifier = RandomForestClassifier(random_state = 123, 
                                        n_estimators = grid.best_params_['n_estimators'], 
                                        max_depth = grid.best_params_['max_depth'],
                                        max_features = grid.best_params_['max_features'], 
                                        min_samples_leaf = grid.best_params_['min_samples_leaf'],
                                        min_samples_split = grid.best_params_['min_samples_split'], 
                                        bootstrap = grid.best_params_['bootstrap'],
                                        criterion = grid.best_params_['criterion'])

    classifier.fit(X_train, y_train)
    
    # pickle the fitted model
    joblib.dump(classifier, 'rf_'+sampName+'.pkl')
    
    # pickle the predicted responses
    y_pred = classifier.predict(X_test)
    y_pred_prob = classifier.predict_proba(X_test)
    
    joblib.dump(y_pred, 'y_pred_'+sampName+'.pkl')
    joblib.dump(y_pred_prob, 'y_pred_prob_'+sampName+'.pkl')
    
    # printout metrics for model performance
    print('Accuracy score: ', accuracy_score(y_test, y_pred))
    
    print('Confusion matrix:\n', confusion_matrix(y_test, y_pred))
    skplt.metrics.plot_confusion_matrix(y_test, y_pred)
    plt.savefig('confusion_matrix_rf.png')
    
    skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize = True)
    plt.savefig('confusion_matrix_rf_norm.png')
    
    print('Classification report:\n', classification_report(y_test, y_pred))
    
    print('ROC_AUC_score: ', roc_auc_score(y_test, y_pred))
    skplt.metrics.plot_roc(y_test, y_pred_prob)
    plt.savefig('roc_rf.png')
    
    skplt.metrics.plot_precision_recall_curve(y_test, y_pred_prob)
    plt.savefig('pr_rf.png')
    
    # printout feature importances
    feature_import = pd.DataFrame(data = classifier.feature_importances_, index = X_test.columns.values, columns = ['values'])
    feature_import.sort_values(['values'], ascending = False, inplace = True)
    feature_import.reset_index(level = 0, inplace = True)
    print(feature_import)
    
    # feature importances plot
    plt.figure(figsize = (35,20))
    sns.set(style = 'white', font_scale = 2)
    
    ax = sns.barplot(x = 'values', y = 'index', data = feature_import, palette = 'deep')
    ax.set_title('Variables Importance Plot of Random Forest')
    plt.savefig('importance_rf.png')
    
    return classifier







########################################################################################################
####################################  call the main function  ##########################################



X_train = joblib.load('X_train_adasyn.pkl')
X_test = pd.read_pickle('X_test.pkl')
y_train = joblib.load('y_train_adasyn.pkl')
y_test = pd.read_pickle('y_test_s.pkl')



classifier_mod(X_train, y_train, X_test, y_test, 'adasyn')
















