###################################################################################################################
# Choose 3 algorithms to stack based on PR_AUC: 1.Random Forest 2. XGBoost 3. Logistic Regression with 'ElasticNet'
####################################################################################################################


import numpy as np
import pandas as pd

import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.externals import joblib

%matplotlib inline
sns.set(style = 'white', font_scale = 0.9)







X_train = joblib.load('X_train_adasyn.pkl')
X_test = pd.read_pickle('X_test.pkl')
y_train = joblib.load('y_train_adasyn.pkl')
y_test = pd.read_pickle('y_test_s.pkl')



print(X_train.shape)
print(X_test.shape)
print(y_train.shape)
print(y_test.shape)




######################################################################################
#############################   stack models    ######################################


from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
from xgboost.sklearn import XGBClassifier
from sklearn.linear_model import SGDClassifier




classifier_rf = RandomForestClassifier(random_state = 123, n_estimators = 500, max_depth = None, max_features = 3, 
                                   min_samples_leaf = 1, min_samples_split = 2, bootstrap = False, criterion = 'gini')

classifier_xgb = XGBClassifier(learning_rate = 0.05, n_estimators = 200, max_depth = 8, min_child_weight = 1, gamma = 0.1, 
                           subsample = 0.7, colsample_bytree = 0.6, 
                           reg_alpha = 1e-5, objective = 'binary:logistic', nthread = 4, seed = 123)


classifier_lr = SGDClassifier(loss = 'log', random_state = 123, n_iter = 2000, alpha = 0.01, penalty = 'elasticnet')



from mlxtend.classifier import EnsembleVoteClassifier

eclf = EnsembleVoteClassifier(clfs = [classifier_rf, classifier_xgb, classifier_lr], voting = 'soft')
eclf.fit(X_train, y_train)






from sklearn.externals import joblib

joblib.dump(eclf, 'stack_smote.pkl')






y_pred = eclf.predict(X_test)
y_pred_prob = eclf.predict_proba(X_test)

joblib.dump(y_pred, 'y_pred_stack.pkl')
joblib.dump(y_pred_prob, 'y_pred_proba_stack.pkl')





#############################################################################################
######################     model performance   ##############################################


from sklearn.metrics import accuracy_score

print('Accuracy score: ', accuracy_score(y_test, y_pred))




from sklearn.metrics import confusion_matrix

print('Confusion matrix:\n', confusion_matrix(y_test, y_pred))




import scikitplot as skplt

skplt.metrics.plot_confusion_matrix(y_test, y_pred)
plt.savefig('confusion_matrix_eclf.png')



skplt.metrics.plot_confusion_matrix(y_test, y_pred, normalize = True)
plt.savefig('confusion_matrix_norm_eclf.png')



from sklearn.metrics import classification_report

print('Classification report:\n', classification_report(y_test, y_pred))




from sklearn.metrics import roc_auc_score

print('ROC_AUC_score: ', roc_auc_score(y_test, y_pred))





import scikitplot as skplt

skplt.metrics.plot_roc(y_test, y_pred_prob)
plt.savefig('roc_auc_eclf.png')




import scikitplot as skplt

skplt.metrics.plot_precision_recall_curve(y_test, y_pred_prob)
plt.savefig('pr_auc_eclf.png')































